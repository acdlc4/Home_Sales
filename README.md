# Home Sales Challenge (Module 22)

## Overview
Using SparkSQL, this challenge is to determine key metrics about the provided home sales data. In using Spark, several tasks will be completed, including creating temporary views, partitioning the data, performing the cache and uncache a temporary table, and verifying that the table has been uncached.

---
## Key Questions to Be Addressed
1) What is the average price for a four-bedroom house sold for each year?

2) What is the average price of a home for each year the home was built, that has three bedrooms and three bathrooms?

3) What is the average price of a home for each year the home was built, that has three bedrooms, three bathrooms, two floors, and is greater than or equal to 2,000 square feet?

4) What is the average price of a home per "view" rating having an average home price greater than or equal to $350,000?

---
## Summary
- Results can be found in the Jupyter Notebook at the location provided below

##
### File locations
#### Jupyter notebooks:
- https://github.com/acdlc4/Home_Sales/blob/main/Home_Sales.ipynb

#### Apache Parquet files:
- https://github.com/acdlc4/Home_Sales/blob/main/home_sales_p/

#### AWS S3 data source:
- https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv
--- 
### Any questions?

Feel free to send a message to acdlc4@gmail.com with any questions / comments. Inspiration and credit for any code used is from work done during my attendance in the 2024 Northwestern University Data Analysis Bootcamp class sessions.


